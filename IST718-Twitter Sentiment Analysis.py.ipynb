{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "  The tweets.csv file contains the following columns:\n",
    " - target: the polarity of the tweet (0 = negative, 4 = positive)\n",
    " - ids: The id of the tweet ( 2087)\n",
    " - date: the date of the tweet (Sat May 16 23:58:44 UTC 2009)\n",
    " - flag: The query (lyx). If there is no query, then this value is NO_QUERY.\n",
    " - user: the user that tweeted (robotickilldozr)\n",
    " - text: the text of the tweet (Lyx is cool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ZewYvC7KfoKB",
    "outputId": "71d75e50-d9a7-4cbd-dc84-94cb3a7576d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "  Downloading https://files.pythonhosted.org/packages/f0/26/198fc8c0b98580f617cb03cb298c6056587b8f0447e20fa40c5b634ced77/pyspark-3.0.1.tar.gz (204.2MB)\n",
      "Collecting py4j==0.10.9\n",
      "  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
      "Building wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py): started\n",
      "  Building wheel for pyspark (setup.py): finished with status 'done'\n",
      "  Created wheel for pyspark: filename=pyspark-3.0.1-py2.py3-none-any.whl size=204612243 sha256=eec98efcfa94d262d86dc4ac12f7b0a5154697e0a3767ea46a098666cffb8f62\n",
      "  Stored in directory: /root/.cache/pip/wheels/5e/bd/07/031766ca628adec8435bb40f0bd83bb676ce65ff4007f8e73f\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9 pyspark-3.0.1\n",
      "tweets.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2020-10-21 20:42:37--  https://raw.githubusercontent.com/wewilli1/ist718_data/master/tweets.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 13727793 (13M) [text/plain]\n",
      "Saving to: ‘tweets.csv’\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  0% 1.97M 7s\n",
      "    50K .......... .......... .......... .......... ..........  0% 4.40M 5s\n",
      "   100K .......... .......... .......... .......... ..........  1% 10.9M 4s\n",
      "   150K .......... .......... .......... .......... ..........  1% 6.81M 3s\n",
      "   200K .......... .......... .......... .......... ..........  1% 7.20M 3s\n",
      "   250K .......... .......... .......... .......... ..........  2% 9.52M 3s\n",
      "   300K .......... .......... .......... .......... ..........  2% 8.41M 2s\n",
      "   350K .......... .......... .......... .......... ..........  2% 11.5M 2s\n",
      "   400K .......... .......... .......... .......... ..........  3% 8.44M 2s\n",
      "   450K .......... .......... .......... .......... ..........  3% 11.8M 2s\n",
      "   500K .......... .......... .......... .......... ..........  4% 8.18M 2s\n",
      "   550K .......... .......... .......... .......... ..........  4% 8.30M 2s\n",
      "   600K .......... .......... .......... .......... ..........  4% 10.6M 2s\n",
      "   650K .......... .......... .......... .......... ..........  5% 10.4M 2s\n",
      "   700K .......... .......... .......... .......... ..........  5% 12.5M 2s\n",
      "   750K .......... .......... .......... .......... ..........  5% 10.7M 2s\n",
      "   800K .......... .......... .......... .......... ..........  6% 10.4M 2s\n",
      "   850K .......... .......... .......... .......... ..........  6% 14.5M 2s\n",
      "   900K .......... .......... .......... .......... ..........  7% 8.85M 2s\n",
      "   950K .......... .......... .......... .......... ..........  7% 10.2M 2s\n",
      "  1000K .......... .......... .......... .......... ..........  7% 10.2M 2s\n",
      "  1050K .......... .......... .......... .......... ..........  8% 15.4M 2s\n",
      "  1100K .......... .......... .......... .......... ..........  8% 12.1M 1s\n",
      "  1150K .......... .......... .......... .......... ..........  8% 9.20M 1s\n",
      "  1200K .......... .......... .......... .......... ..........  9% 13.9M 1s\n",
      "  1250K .......... .......... .......... .......... ..........  9% 19.4M 1s\n",
      "  1300K .......... .......... .......... .......... .......... 10% 8.48M 1s\n",
      "  1350K .......... .......... .......... .......... .......... 10% 12.3M 1s\n",
      "  1400K .......... .......... .......... .......... .......... 10% 14.8M 1s\n",
      "  1450K .......... .......... .......... .......... .......... 11% 10.8M 1s\n",
      "  1500K .......... .......... .......... .......... .......... 11% 20.1M 1s\n",
      "  1550K .......... .......... .......... .......... .......... 11% 13.5M 1s\n",
      "  1600K .......... .......... .......... .......... .......... 12% 16.1M 1s\n",
      "  1650K .......... .......... .......... .......... .......... 12% 10.8M 1s\n",
      "  1700K .......... .......... .......... .......... .......... 13% 26.8M 1s\n",
      "  1750K .......... .......... .......... .......... .......... 13% 11.6M 1s\n",
      "  1800K .......... .......... .......... .......... .......... 13% 10.2M 1s\n",
      "  1850K .......... .......... .......... .......... .......... 14% 26.4M 1s\n",
      "  1900K .......... .......... .......... .......... .......... 14% 12.3M 1s\n",
      "  1950K .......... .......... .......... .......... .......... 14% 22.1M 1s\n",
      "  2000K .......... .......... .......... .......... .......... 15% 11.1M 1s\n",
      "  2050K .......... .......... .......... .......... .......... 15% 22.1M 1s\n",
      "  2100K .......... .......... .......... .......... .......... 16% 15.1M 1s\n",
      "  2150K .......... .......... .......... .......... .......... 16% 15.3M 1s\n",
      "  2200K .......... .......... .......... .......... .......... 16% 12.3M 1s\n",
      "  2250K .......... .......... .......... .......... .......... 17% 17.5M 1s\n",
      "  2300K .......... .......... .......... .......... .......... 17% 21.8M 1s\n",
      "  2350K .......... .......... .......... .......... .......... 17% 15.6M 1s\n",
      "  2400K .......... .......... .......... .......... .......... 18% 12.4M 1s\n",
      "  2450K .......... .......... .......... .......... .......... 18% 23.2M 1s\n",
      "  2500K .......... .......... .......... .......... .......... 19% 18.7M 1s\n",
      "  2550K .......... .......... .......... .......... .......... 19% 15.6M 1s\n",
      "  2600K .......... .......... .......... .......... .......... 19% 12.2M 1s\n",
      "  2650K .......... .......... .......... .......... .......... 20% 22.7M 1s\n",
      "  2700K .......... .......... .......... .......... .......... 20% 18.1M 1s\n",
      "  2750K .......... .......... .......... .......... .......... 20% 19.3M 1s\n",
      "  2800K .......... .......... .......... .......... .......... 21% 16.3M 1s\n",
      "  2850K .......... .......... .......... .......... .......... 21% 19.0M 1s\n",
      "  2900K .......... .......... .......... .......... .......... 22% 27.2M 1s\n",
      "  2950K .......... .......... .......... .......... .......... 22% 18.3M 1s\n",
      "  3000K .......... .......... .......... .......... .......... 22% 15.9M 1s\n",
      "  3050K .......... .......... .......... .......... .......... 23% 19.1M 1s\n",
      "  3100K .......... .......... .......... .......... .......... 23% 18.7M 1s\n",
      "  3150K .......... .......... .......... .......... .......... 23% 22.5M 1s\n",
      "  3200K .......... .......... .......... .......... .......... 24% 29.9M 1s\n",
      "  3250K .......... .......... .......... .......... .......... 24% 18.9M 1s\n",
      "  3300K .......... .......... .......... .......... .......... 24% 12.3M 1s\n",
      "  3350K .......... .......... .......... .......... .......... 25% 22.6M 1s\n",
      "  3400K .......... .......... .......... .......... .......... 25% 33.8M 1s\n",
      "  3450K .......... .......... .......... .......... .......... 26% 25.4M 1s\n",
      "  3500K .......... .......... .......... .......... .......... 26% 18.6M 1s\n",
      "  3550K .......... .......... .......... .......... .......... 26% 12.3M 1s\n",
      "  3600K .......... .......... .......... .......... .......... 27% 50.2M 1s\n",
      "  3650K .......... .......... .......... .......... .......... 27% 24.0M 1s\n",
      "  3700K .......... .......... .......... .......... .......... 27% 24.0M 1s\n",
      "  3750K .......... .......... .......... .......... .......... 28% 17.4M 1s\n",
      "  3800K .......... .......... .......... .......... .......... 28% 12.5M 1s\n",
      "  3850K .......... .......... .......... .......... .......... 29% 42.0M 1s\n",
      "  3900K .......... .......... .......... .......... .......... 29% 21.1M 1s\n",
      "  3950K .......... .......... .......... .......... .......... 29% 56.6M 1s\n",
      "  4000K .......... .......... .......... .......... .......... 30% 17.4M 1s\n",
      "  4050K .......... .......... .......... .......... .......... 30% 30.5M 1s\n",
      "  4100K .......... .......... .......... .......... .......... 30% 14.4M 1s\n",
      "  4150K .......... .......... .......... .......... .......... 31% 27.3M 1s\n",
      "  4200K .......... .......... .......... .......... .......... 31% 27.1M 1s\n",
      "  4250K .......... .......... .......... .......... .......... 32% 27.5M 1s\n",
      "  4300K .......... .......... .......... .......... .......... 32% 32.1M 1s\n",
      "  4350K .......... .......... .......... .......... .......... 32% 12.1M 1s\n",
      "  4400K .......... .......... .......... .......... .......... 33% 37.4M 1s\n",
      "  4450K .......... .......... .......... .......... .......... 33% 28.4M 1s\n",
      "  4500K .......... .......... .......... .......... .......... 33% 27.2M 1s\n",
      "  4550K .......... .......... .......... .......... .......... 34% 30.8M 1s\n",
      "  4600K .......... .......... .......... .......... .......... 34% 14.4M 1s\n",
      "  4650K .......... .......... .......... .......... .......... 35%  101M 1s\n",
      "  4700K .......... .......... .......... .......... .......... 35% 16.0M 1s\n",
      "  4750K .......... .......... .......... .......... .......... 35% 42.9M 1s\n",
      "  4800K .......... .......... .......... .......... .......... 36% 38.6M 1s\n",
      "  4850K .......... .......... .......... .......... .......... 36% 22.4M 1s\n",
      "  4900K .......... .......... .......... .......... .......... 36% 33.6M 1s\n",
      "  4950K .......... .......... .......... .......... .......... 37% 17.7M 1s\n",
      "  5000K .......... .......... .......... .......... .......... 37% 24.9M 1s\n",
      "  5050K .......... .......... .......... .......... .......... 38% 22.1M 1s\n",
      "  5100K .......... .......... .......... .......... .......... 38% 63.2M 1s\n",
      "  5150K .......... .......... .......... .......... .......... 38% 25.0M 1s\n",
      "  5200K .......... .......... .......... .......... .......... 39% 35.1M 1s\n",
      "  5250K .......... .......... .......... .......... .......... 39% 37.6M 1s\n",
      "  5300K .......... .......... .......... .......... .......... 39% 23.1M 1s\n",
      "  5350K .......... .......... .......... .......... .......... 40% 22.8M 1s\n",
      "  5400K .......... .......... .......... .......... .......... 40% 20.5M 1s\n",
      "  5450K .......... .......... .......... .......... .......... 41% 63.7M 1s\n",
      "  5500K .......... .......... .......... .......... .......... 41% 25.4M 1s\n",
      "  5550K .......... .......... .......... .......... .......... 41% 41.1M 1s\n",
      "  5600K .......... .......... .......... .......... .......... 42% 29.0M 1s\n",
      "  5650K .......... .......... .......... .......... .......... 42% 25.2M 1s\n",
      "  5700K .......... .......... .......... .......... .......... 42% 20.6M 0s\n",
      "  5750K .......... .......... .......... .......... .......... 43% 23.8M 0s\n",
      "  5800K .......... .......... .......... .......... .......... 43% 58.4M 0s\n",
      "  5850K .......... .......... .......... .......... .......... 44% 23.3M 0s\n",
      "  5900K .......... .......... .......... .......... .......... 44% 41.7M 0s\n",
      "  5950K .......... .......... .......... .......... .......... 44% 36.8M 0s\n",
      "  6000K .......... .......... .......... .......... .......... 45% 23.7M 0s\n",
      "  6050K .......... .......... .......... .......... .......... 45% 38.8M 0s\n",
      "  6100K .......... .......... .......... .......... .......... 45% 17.7M 0s\n",
      "  6150K .......... .......... .......... .......... .......... 46% 44.9M 0s\n",
      "  6200K .......... .......... .......... .......... .......... 46% 32.4M 0s\n",
      "  6250K .......... .......... .......... .......... .......... 46% 28.5M 0s\n",
      "  6300K .......... .......... .......... .......... .......... 47% 41.6M 0s\n",
      "  6350K .......... .......... .......... .......... .......... 47%  101M 0s\n",
      "  6400K .......... .......... .......... .......... .......... 48% 24.3M 0s\n",
      "  6450K .......... .......... .......... .......... .......... 48% 28.7M 0s\n",
      "  6500K .......... .......... .......... .......... .......... 48% 21.3M 0s\n",
      "  6550K .......... .......... .......... .......... .......... 49% 28.4M 0s\n",
      "  6600K .......... .......... .......... .......... .......... 49% 56.0M 0s\n",
      "  6650K .......... .......... .......... .......... .......... 49% 26.0M 0s\n",
      "  6700K .......... .......... .......... .......... .......... 50% 35.6M 0s\n",
      "  6750K .......... .......... .......... .......... .......... 50% 58.3M 0s\n",
      "  6800K .......... .......... .......... .......... .......... 51% 97.3M 0s\n",
      "  6850K .......... .......... .......... .......... .......... 51% 22.0M 0s\n",
      "  6900K .......... .......... .......... .......... .......... 51% 17.4M 0s\n",
      "  6950K .......... .......... .......... .......... .......... 52% 31.4M 0s\n",
      "  7000K .......... .......... .......... .......... .......... 52% 66.1M 0s\n",
      "  7050K .......... .......... .......... .......... .......... 52% 53.8M 0s\n",
      "  7100K .......... .......... .......... .......... .......... 53% 35.3M 0s\n",
      "  7150K .......... .......... .......... .......... .......... 53% 26.5M 0s\n",
      "  7200K .......... .......... .......... .......... .......... 54% 63.7M 0s\n",
      "  7250K .......... .......... .......... .......... .......... 54% 57.2M 0s\n",
      "  7300K .......... .......... .......... .......... .......... 54% 31.9M 0s\n",
      "  7350K .......... .......... .......... .......... .......... 55% 20.2M 0s\n",
      "  7400K .......... .......... .......... .......... .......... 55% 28.9M 0s\n",
      "  7450K .......... .......... .......... .......... .......... 55% 64.6M 0s\n",
      "  7500K .......... .......... .......... .......... .......... 56% 34.7M 0s\n",
      "  7550K .......... .......... .......... .......... .......... 56% 76.0M 0s\n",
      "  7600K .......... .......... .......... .......... .......... 57% 20.4M 0s\n",
      "  7650K .......... .......... .......... .......... .......... 57%  128M 0s\n",
      "  7700K .......... .......... .......... .......... .......... 57% 28.1M 0s\n",
      "  7750K .......... .......... .......... .......... .......... 58% 53.4M 0s\n",
      "  7800K .......... .......... .......... .......... .......... 58% 20.5M 0s\n",
      "  7850K .......... .......... .......... .......... .......... 58% 33.8M 0s\n",
      "  7900K .......... .......... .......... .......... .......... 59%  125M 0s\n",
      "  7950K .......... .......... .......... .......... .......... 59% 30.5M 0s\n",
      "  8000K .......... .......... .......... .......... .......... 60% 65.0M 0s\n",
      "  8050K .......... .......... .......... .......... .......... 60% 24.3M 0s\n",
      "  8100K .......... .......... .......... .......... .......... 60% 38.5M 0s\n",
      "  8150K .......... .......... .......... .......... .......... 61% 29.8M 0s\n",
      "  8200K .......... .......... .......... .......... .......... 61%  135M 0s\n",
      "  8250K .......... .......... .......... .......... .......... 61% 59.8M 0s\n",
      "  8300K .......... .......... .......... .......... .......... 62% 22.0M 0s\n",
      "  8350K .......... .......... .......... .......... .......... 62% 40.5M 0s\n",
      "  8400K .......... .......... .......... .......... .......... 63% 46.4M 0s\n",
      "  8450K .......... .......... .......... .......... .......... 63% 59.4M 0s\n",
      "  8500K .......... .......... .......... .......... .......... 63% 44.2M 0s\n",
      "  8550K .......... .......... .......... .......... .......... 64% 29.7M 0s\n",
      "  8600K .......... .......... .......... .......... .......... 64% 37.5M 0s\n",
      "  8650K .......... .......... .......... .......... .......... 64% 46.2M 0s\n",
      "  8700K .......... .......... .......... .......... .......... 65% 60.9M 0s\n",
      "  8750K .......... .......... .......... .......... .......... 65% 50.3M 0s\n",
      "  8800K .......... .......... .......... .......... .......... 66% 23.7M 0s\n",
      "  8850K .......... .......... .......... .......... .......... 66% 76.2M 0s\n",
      "  8900K .......... .......... .......... .......... .......... 66% 41.1M 0s\n",
      "  8950K .......... .......... .......... .......... .......... 67% 32.6M 0s\n",
      "  9000K .......... .......... .......... .......... .......... 67% 69.7M 0s\n",
      "  9050K .......... .......... .......... .......... .......... 67% 32.6M 0s\n",
      "  9100K .......... .......... .......... .......... .......... 68% 95.4M 0s\n",
      "  9150K .......... .......... .......... .......... .......... 68% 38.1M 0s\n",
      "  9200K .......... .......... .......... .......... .......... 68% 27.9M 0s\n",
      "  9250K .......... .......... .......... .......... .......... 69% 47.0M 0s\n",
      "  9300K .......... .......... .......... .......... .......... 69% 71.7M 0s\n",
      "  9350K .......... .......... .......... .......... .......... 70% 32.9M 0s\n",
      "  9400K .......... .......... .......... .......... .......... 70% 40.1M 0s\n",
      "  9450K .......... .......... .......... .......... .......... 70% 28.7M 0s\n",
      "  9500K .......... .......... .......... .......... .......... 71% 50.8M 0s\n",
      "  9550K .......... .......... .......... .......... .......... 71% 64.6M 0s\n",
      "  9600K .......... .......... .......... .......... .......... 71% 59.8M 0s\n",
      "  9650K .......... .......... .......... .......... .......... 72% 26.7M 0s\n",
      "  9700K .......... .......... .......... .......... .......... 72% 72.3M 0s\n",
      "  9750K .......... .......... .......... .......... .......... 73% 41.7M 0s\n",
      "  9800K .......... .......... .......... .......... .......... 73% 57.2M 0s\n",
      "  9850K .......... .......... .......... .......... .......... 73% 68.6M 0s\n",
      "  9900K .......... .......... .......... .......... .......... 74% 41.0M 0s\n",
      "  9950K .......... .......... .......... .......... .......... 74% 32.7M 0s\n",
      " 10000K .......... .......... .......... .......... .......... 74%  218M 0s\n",
      " 10050K .......... .......... .......... .......... .......... 75% 11.2M 0s\n",
      " 10100K .......... .......... .......... .......... .......... 75%  228M 0s\n",
      " 10150K .......... .......... .......... .......... .......... 76%  171M 0s\n",
      " 10200K .......... .......... .......... .......... .......... 76% 42.0M 0s\n",
      " 10250K .......... .......... .......... .......... .......... 76% 59.7M 0s\n",
      " 10300K .......... .......... .......... .......... .......... 77%  207M 0s\n",
      " 10350K .......... .......... .......... .......... .......... 77% 38.6M 0s\n",
      " 10400K .......... .......... .......... .......... .......... 77% 69.8M 0s\n",
      " 10450K .......... .......... .......... .......... .......... 78% 42.8M 0s\n",
      " 10500K .......... .......... .......... .......... .......... 78%  218M 0s\n",
      " 10550K .......... .......... .......... .......... .......... 79% 37.2M 0s\n",
      " 10600K .......... .......... .......... .......... .......... 79% 10.7M 0s\n",
      " 10650K .......... .......... .......... .......... .......... 79% 96.9M 0s\n",
      " 10700K .......... .......... .......... .......... .......... 80% 47.3M 0s\n",
      " 10750K .......... .......... .......... .......... .......... 80%  122M 0s\n",
      " 10800K .......... .......... .......... .......... .......... 80% 40.1M 0s\n",
      " 10850K .......... .......... .......... .......... .......... 81% 59.5M 0s\n",
      " 10900K .......... .......... .......... .......... .......... 81% 33.9M 0s\n",
      " 10950K .......... .......... .......... .......... .......... 82% 78.4M 0s\n",
      " 11000K .......... .......... .......... .......... .......... 82% 85.1M 0s\n",
      " 11050K .......... .......... .......... .......... .......... 82% 60.6M 0s\n",
      " 11100K .......... .......... .......... .......... .......... 83% 49.5M 0s\n",
      " 11150K .......... .......... .......... .......... .......... 83% 49.4M 0s\n",
      " 11200K .......... .......... .......... .......... .......... 83%  216M 0s\n",
      " 11250K .......... .......... .......... .......... .......... 84% 18.9M 0s\n",
      " 11300K .......... .......... .......... .......... .......... 84% 36.3M 0s\n",
      " 11350K .......... .......... .......... .......... .......... 85% 49.2M 0s\n",
      " 11400K .......... .......... .......... .......... .......... 85% 97.8M 0s\n",
      " 11450K .......... .......... .......... .......... .......... 85%  142M 0s\n",
      " 11500K .......... .......... .......... .......... .......... 86% 48.7M 0s\n",
      " 11550K .......... .......... .......... .......... .......... 86% 44.7M 0s\n",
      " 11600K .......... .......... .......... .......... .......... 86% 46.7M 0s\n",
      " 11650K .......... .......... .......... .......... .......... 87% 54.4M 0s\n",
      " 11700K .......... .......... .......... .......... .......... 87% 65.9M 0s\n",
      " 11750K .......... .......... .......... .......... .......... 88% 88.0M 0s\n",
      " 11800K .......... .......... .......... .......... .......... 88% 47.6M 0s\n",
      " 11850K .......... .......... .......... .......... .......... 88% 11.5M 0s\n",
      " 11900K .......... .......... .......... .......... .......... 89% 69.5M 0s\n",
      " 11950K .......... .......... .......... .......... .......... 89%  116M 0s\n",
      " 12000K .......... .......... .......... .......... .......... 89% 52.0M 0s\n",
      " 12050K .......... .......... .......... .......... .......... 90% 27.6M 0s\n",
      " 12100K .......... .......... .......... .......... .......... 90% 57.5M 0s\n",
      " 12150K .......... .......... .......... .......... .......... 91% 52.7M 0s\n",
      " 12200K .......... .......... .......... .......... .......... 91%  204M 0s\n",
      " 12250K .......... .......... .......... .......... .......... 91% 40.2M 0s\n",
      " 12300K .......... .......... .......... .......... .......... 92% 23.2M 0s\n",
      " 12350K .......... .......... .......... .......... .......... 92%  112M 0s\n",
      " 12400K .......... .......... .......... .......... .......... 92%  113M 0s\n",
      " 12450K .......... .......... .......... .......... .......... 93% 64.7M 0s\n",
      " 12500K .......... .......... .......... .......... .......... 93% 40.9M 0s\n",
      " 12550K .......... .......... .......... .......... .......... 93% 25.4M 0s\n",
      " 12600K .......... .......... .......... .......... .......... 94% 94.5M 0s\n",
      " 12650K .......... .......... .......... .......... .......... 94%  210M 0s\n",
      " 12700K .......... .......... .......... .......... .......... 95% 51.7M 0s\n",
      " 12750K .......... .......... .......... .......... .......... 95% 50.4M 0s\n",
      " 12800K .......... .......... .......... .......... .......... 95% 45.5M 0s\n",
      " 12850K .......... .......... .......... .......... .......... 96%  194M 0s\n",
      " 12900K .......... .......... .......... .......... .......... 96% 42.0M 0s\n",
      " 12950K .......... .......... .......... .......... .......... 96% 24.7M 0s\n",
      " 13000K .......... .......... .......... .......... .......... 97%  220M 0s\n",
      " 13050K .......... .......... .......... .......... .......... 97%  101M 0s\n",
      " 13100K .......... .......... .......... .......... .......... 98% 86.9M 0s\n",
      " 13150K .......... .......... .......... .......... .......... 98% 66.1M 0s\n",
      " 13200K .......... .......... .......... .......... .......... 98% 48.5M 0s\n",
      " 13250K .......... .......... .......... .......... .......... 99% 26.4M 0s\n",
      " 13300K .......... .......... .......... .......... .......... 99%  207M 0s\n",
      " 13350K .......... .......... .......... .......... .......... 99%  120M 0s\n",
      " 13400K ......                                                100% 11535G=0.6s\n",
      "\n",
      "2020-10-21 20:42:38 (23.6 MB/s) - ‘tweets.csv’ saved [13727793/13727793]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Need to install pyspark\n",
    "# if pyspark is already installed, will print a message indicating pyspark already isntalled\n",
    "pip install pyspark\n",
    "\n",
    "# Download tweets.csv from github\n",
    "# If the tweets.csv file does not exist in the colab environment\n",
    "if [[ ! -f ./tweets.csv ]]; then \n",
    "   # download tweets.csv file from github and save it in this colab environment instance\n",
    "   wget https://raw.githubusercontent.com/wewilli1/ist718_data/master/tweets.csv   \n",
    "fi\n",
    "\n",
    "# vefify tweets.csv exits in the colab env - should not print an error message\n",
    "ls tweets.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZodRqBZofvYJ"
   },
   "outputs": [],
   "source": [
    "# import statements\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "id": "RTcQGJktfyoA",
    "outputId": "8d8b5c8f-e7b5-4cff-d91c-7b22fb498816"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(target='4', id='1467822272', date='Mon Apr 06 22:22:45 PDT 2009', flag='NO_QUERY', user='ersle', text='I LOVE @Health4UandPets u guys r the best!! '),\n",
       " Row(target='4', id='1467822273', date='Mon Apr 06 22:22:45 PDT 2009', flag='NO_QUERY', user='becca210', text='im meeting up with one of my besties tonight! Cant wait!!  - GIRL TALK!!'),\n",
       " Row(target='4', id='1467822283', date='Mon Apr 06 22:22:46 PDT 2009', flag='NO_QUERY', user='Wingman29', text='@DaRealSunisaKim Thanks for the Twitter add, Sunisa! I got to meet you once at a HIN show here in the DC area and you were a sweetheart. '),\n",
       " Row(target='4', id='1467822287', date='Mon Apr 06 22:22:46 PDT 2009', flag='NO_QUERY', user='katarinka', text='Being sick can be really cheap when it hurts too much to eat real food  Plus, your friends make you soup'),\n",
       " Row(target='4', id='1467822293', date='Mon Apr 06 22:22:46 PDT 2009', flag='NO_QUERY', user='_EmilyYoung', text='@LovesBrooklyn2 he has that effect on everyone ')]"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example code to read the downloaded tweets.csv file on colab\n",
    "tweets_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"tweets.csv\")\n",
    "tweets_df.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z_ek8izKfk3h"
   },
   "outputs": [],
   "source": [
    "enable_grid = True\n",
    "%matplotlib inline\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sqlContext = SQLContext(sc)\n",
    "import os\n",
    "\n",
    "# Define a function to determine if we are running on data bricks\n",
    "# Return true if running in the data bricks environment, false otherwise\n",
    "def is_databricks():\n",
    "    # get the databricks runtime version\n",
    "    db_env = os.getenv(\"DATABRICKS_RUNTIME_VERSION\")\n",
    "    \n",
    "    # if running on data bricks\n",
    "    if db_env != None:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Define a function to read the data file.  The full path data file name is constructed\n",
    "# by checking runtime environment variables to determine if the runtime environment is \n",
    "# databricks, or a student's personal computer.  The full path file name is then\n",
    "# constructed based on the runtime env.\n",
    "# \n",
    "# Params\n",
    "#   data_file_name: The base name of the data file to load\n",
    "# \n",
    "# Returns the full path file name based on the runtime env\n",
    "#\n",
    "# Correct Usage Example (pass ONLY the full file name):\n",
    "#   file_name_to_load = get_training_filename(\"sms_spam.csv\") # correct - pass ONLY the full file name  \n",
    "#   \n",
    "# Incorrect Usage Example\n",
    "#   file_name_to_load = get_training_filename(\"/sms_spam.csv\") # incorrect - pass ONLY the full file name\n",
    "#   file_name_to_load = get_training_filename(\"sms_spam.csv/\") # incorrect - pass ONLY the full file name\n",
    "#   file_name_to_load = get_training_filename(\"c:/users/will/data/sms_spam.csv\") incorrect -pass ONLY the full file name\n",
    "def get_training_filename(data_file_name):    \n",
    "    # if running on data bricks\n",
    "    if is_databricks():\n",
    "        # build the full path file name assuming data brick env\n",
    "        full_path_name = \"dbfs:/FileStore/tables/%s\" % data_file_name\n",
    "    # else the data is assumed to be in the same dir as this notebook\n",
    "    else:\n",
    "        # Assume the student is running on their own computer and load the data\n",
    "        # file from the same dir as this notebook\n",
    "        full_path_name = data_file_name\n",
    "    \n",
    "    # return the full path file name to the caller\n",
    "    return full_path_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "abylIWkPy3tC"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as fn\n",
    "import requests\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.ml.feature import IDF\n",
    "from pyspark.ml import feature\n",
    "from pyspark.ml import classification\n",
    "from pyspark.ml import feature, regression, evaluation, Pipeline\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "import pandas as pd\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "p_-5MQRhfk3n",
    "outputId": "fddda9a2-7f2b-475a-e6d1-1d114a45c220"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|target|\n",
      "+------+\n",
      "|     1|\n",
      "|     0|\n",
      "+------+\n",
      "\n",
      "+------+-----+----------+\n",
      "|target|count|percentage|\n",
      "+------+-----+----------+\n",
      "|     1|50000|      50.0|\n",
      "|     0|50000|      50.0|\n",
      "+------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(get_training_filename(\"tweets.csv\")).drop('id', 'date', 'flag', 'user')\n",
    "\n",
    "# transform 4 to 1\n",
    "tweets_df = tweets_df.withColumn('target', fn.regexp_replace(fn.col('target'), '4', '1'))\n",
    "# change data type to integer\n",
    "tweets_df = tweets_df.withColumn('target', fn.col('target').cast('Integer'))\n",
    "\n",
    "# check transformation\n",
    "tweets_df.select('target').distinct().show()\n",
    "# count and percentage of positive and negative tweets\n",
    "tweets_df.groupBy('target').count().withColumn('percentage', (fn.col('count')/tweets_df.count()*100)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "id": "FqxQ0mqWfk3p",
    "outputId": "be668dab-6b52-4a03-cdbf-668cc8116c06"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>I LOVE @Health4UandPets u guys r the best!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>im meeting up with one of my besties tonight! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>@DaRealSunisaKim Thanks for the Twitter add, S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Being sick can be really cheap when it hurts t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>@LovesBrooklyn2 he has that effect on everyone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text\n",
       "0       1       I LOVE @Health4UandPets u guys r the best!! \n",
       "1       1  im meeting up with one of my besties tonight! ...\n",
       "2       1  @DaRealSunisaKim Thanks for the Twitter add, S...\n",
       "3       1  Being sick can be really cheap when it hurts t...\n",
       "4       1    @LovesBrooklyn2 he has that effect on everyone "
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 2)\n"
     ]
    }
   ],
   "source": [
    "tweets_pd = tweets_df.toPandas()\n",
    "display(tweets_pd.head())\n",
    "print(tweets_pd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "id": "gzO_N22Tfk3t",
    "outputId": "1c77fe0e-5e73-4ab2-b487-27b822506551"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|target|                text|               words|            filtered|                  tf|               tfidf|\n",
      "+------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|     1|I LOVE @Health4Ua...|[i, love, @health...|[love, @health4ua...|(13693,[11,19,145...|(13693,[11,19,145...|\n",
      "|     1|im meeting up wit...|[im, meeting, up,...|[im, meeting, bes...|(13693,[0,5,15,24...|(13693,[0,5,15,24...|\n",
      "|     1|@DaRealSunisaKim ...|[@darealsunisakim...|[@darealsunisakim...|(13693,[9,29,31,2...|(13693,[9,29,31,2...|\n",
      "|     1|Being sick can be...|[being, sick, can...|[sick, really, ch...|(13693,[0,14,41,9...|(13693,[0,14,41,9...|\n",
      "|     1|@LovesBrooklyn2 h...|[@lovesbrooklyn2,...|[@lovesbrooklyn2,...|(13693,[2793],[1.0])|(13693,[2793],[8....|\n",
      "|     1|@ProductOfFear Yo...|[@productoffear, ...|[@productoffear, ...|(13693,[0,1,14,29...|(13693,[0,1,14,29...|\n",
      "|     1|@r_keith_hill Tha...|[@r_keith_hill, t...|[@r_keith_hill, t...|(13693,[707,9366]...|(13693,[707,9366]...|\n",
      "|     1|@KeepinUpWKris I ...|[@keepinupwkris, ...|[@keepinupwkris, ...|(13693,[4,11,13,2...|(13693,[4,11,13,2...|\n",
      "|     1|@tommcfly ah, con...|[@tommcfly, ah,, ...|[@tommcfly, ah,, ...|(13693,[31,113,36...|(13693,[31,113,36...|\n",
      "|     1|@e4VoIP I RESPOND...|[@e4voip, i, resp...|[@e4voip, respond...|(13693,[0,262,593...|(13693,[0,262,593...|\n",
      "|     1|crazy day of scho...|[crazy, day, of, ...|[crazy, day, scho...|(13693,[8,46,81,9...|(13693,[8,46,81,9...|\n",
      "|     1|@naughtyhaughty H...|[@naughtyhaughty,...|[@naughtyhaughty,...|(13693,[11,42,348...|(13693,[11,42,348...|\n",
      "|     1|@nileyjileyluver ...|[@nileyjileyluver...|[@nileyjileyluver...|(13693,[12,129,38...|(13693,[12,129,38...|\n",
      "|     1|@soundwav2010 At ...|[@soundwav2010, a...|[@soundwav2010, w...|(13693,[70,146,21...|(13693,[70,146,21...|\n",
      "|     1|@LutheranLucciol ...|[@lutheranlucciol...|[@lutheranlucciol...|(13693,[0,12,35,4...|(13693,[0,12,35,4...|\n",
      "|     1|Just added tweeti...|[just, added, twe...|[just, added, twe...|(13693,[1,18,413,...|(13693,[1,18,413,...|\n",
      "|     1|@michellardi i re...|[@michellardi, i,...|[@michellardi, re...|(13693,[0,12,14,2...|(13693,[0,12,14,2...|\n",
      "|     1|@nicolerichie: yo...|[@nicolerichie:, ...|[@nicolerichie:, ...|(13693,[324,471],...|(13693,[324,471],...|\n",
      "|     1|Catching Up on Em...|[catching, up, on...|[catching, emails...|(13693,[2,97,128,...|(13693,[2,97,128,...|\n",
      "|     1|Dancing around th...|[dancing, around,...|[dancing, room, p...|(13693,[38,331,89...|(13693,[38,331,89...|\n",
      "+------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "num words:  13693\n",
      "num rows:  100000\n"
     ]
    }
   ],
   "source": [
    "# tokenize the text column\n",
    "tokenizer = Tokenizer().setInputCol('text').setOutputCol('words')\n",
    "\n",
    "# load stop words\n",
    "stop_words = requests.get('http://ir.dcs.gla.ac.uk/resources/linguistic_utils/stop_words').text.split()\n",
    "stop_words[0:10]\n",
    "\n",
    "# stop words filter\n",
    "sw_filter = StopWordsRemover()\\\n",
    "  .setStopWords(stop_words)\\\n",
    "  .setCaseSensitive(False)\\\n",
    "  .setInputCol(\"words\")\\\n",
    "  .setOutputCol(\"filtered\")\n",
    "\n",
    "# CountVectorizer\n",
    "cv = CountVectorizer(minTF=1., minDF=5.)\\\n",
    "  .setInputCol(\"filtered\")\\\n",
    "  .setOutputCol(\"tf\")\n",
    "\n",
    "# idf\n",
    "idf = IDF().\\\n",
    "    setInputCol('tf').\\\n",
    "    setOutputCol('tfidf')\n",
    "\n",
    "# pipeline\n",
    "tweets_pre_proc_pipe = Pipeline(stages = [tokenizer, sw_filter, cv, idf]).fit(tweets_df)\n",
    "tweets_pre_proc_df = tweets_pre_proc_pipe.transform(tweets_df)\n",
    "tweets_pre_proc_df.show()\n",
    "\n",
    "print('num words: ', len(tweets_pre_proc_pipe.stages[2].vocabulary))\n",
    "print('num rows: ', tweets_pre_proc_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "id": "Hoh2s1ixfk3v",
    "outputId": "cc9a793c-3f00-490b-bb06-8f064882d800"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>words</th>\n",
       "      <th>filtered</th>\n",
       "      <th>tf</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>I LOVE @Health4UandPets u guys r the best!!</td>\n",
       "      <td>[i, love, @health4uandpets, u, guys, r, the, b...</td>\n",
       "      <td>[love, @health4uandpets, u, guys, r, best!!]</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>im meeting up with one of my besties tonight! ...</td>\n",
       "      <td>[im, meeting, up, with, one, of, my, besties, ...</td>\n",
       "      <td>[im, meeting, besties, tonight!, wait!!, , -, ...</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(1.1265280578718189, 0.0, 0.0, 0.0, 0.0, 3.183...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>@DaRealSunisaKim Thanks for the Twitter add, S...</td>\n",
       "      <td>[@darealsunisakim, thanks, for, the, twitter, ...</td>\n",
       "      <td>[@darealsunisakim, thanks, twitter, add,, suni...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Being sick can be really cheap when it hurts t...</td>\n",
       "      <td>[being, sick, can, be, really, cheap, when, it...</td>\n",
       "      <td>[sick, really, cheap, hurts, eat, real, food, ...</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(1.1265280578718189, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>@LovesBrooklyn2 he has that effect on everyone</td>\n",
       "      <td>[@lovesbrooklyn2, he, has, that, effect, on, e...</td>\n",
       "      <td>[@lovesbrooklyn2, effect]</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target  ...                                              tfidf\n",
       "0       1  ...  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "1       1  ...  (1.1265280578718189, 0.0, 0.0, 0.0, 0.0, 3.183...\n",
       "2       1  ...  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "3       1  ...  (1.1265280578718189, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "4       1  ...  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(tweets_pre_proc_df.toPandas().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7OPpZgq7fk3x"
   },
   "source": [
    "Based on the number of words and the size of the dataset, I do not expect the logistic regression model to overfit. There are 13,693 words and the dataset contains 100,000 rows. There are significantly more number of rows than the number of words, therefore, overfitting is not going to be an issue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WqeOOdN2fk3z"
   },
   "outputs": [],
   "source": [
    "# collect all the vocabulary\n",
    "words = tweets_pre_proc_pipe.stages[2].vocabulary\n",
    "# extract idf score\n",
    "idf_score = tweets_pre_proc_pipe.stages[-1].idf\n",
    "\n",
    "# make dataframe and sort by importance (idf score)\n",
    "idf_df = pd.DataFrame({'words': words, 'idf_score': idf_score})\n",
    "least_imp_idf = idf_df.sort_values('idf_score').reset_index(drop=True).head()\n",
    "most_imp_idf = idf_df.sort_values('idf_score', ascending=False).reset_index(drop=True).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "6k7mvJRGfk32",
    "outputId": "f76119f8-c233-458b-8400-ef5c138942a0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>idf_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blended</td>\n",
       "      <td>9.721176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sleeeep</td>\n",
       "      <td>9.721176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>initially</td>\n",
       "      <td>9.721176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nick.</td>\n",
       "      <td>9.721176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>live!</td>\n",
       "      <td>9.721176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       words  idf_score\n",
       "0    blended   9.721176\n",
       "1    sleeeep   9.721176\n",
       "2  initially   9.721176\n",
       "3      nick.   9.721176\n",
       "4      live!   9.721176"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>idf_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>1.126528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>just</td>\n",
       "      <td>2.588812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i'm</td>\n",
       "      <td>2.645649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>good</td>\n",
       "      <td>3.015945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>like</td>\n",
       "      <td>3.113850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  words  idf_score\n",
       "0         1.126528\n",
       "1  just   2.588812\n",
       "2   i'm   2.645649\n",
       "3  good   3.015945\n",
       "4  like   3.113850"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(most_imp_idf)\n",
    "display(least_imp_idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mlGxL90nfk34"
   },
   "source": [
    "IDF stands for Inverse Document Frequency. The IDF score decreases as a term appears in many documents in the corpus. In other words, it penalizes the terms that appear in many documents, thus, making those terms less important by assigning low idf score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "i_lPXrKlfk35",
    "outputId": "7e363ad1-8ac9-4be5-a891-1e9b833fb155"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score:  0.7235763034983279\n"
     ]
    }
   ],
   "source": [
    "# split data\n",
    "training_df, validation_df, testing_df = tweets_df.randomSplit([0.6, 0.3, 0.1], seed=0)\n",
    "\n",
    "# initiate logistic regression\n",
    "lr = LogisticRegression().\\\n",
    "    setLabelCol('target').\\\n",
    "    setFeaturesCol('tfidf').\\\n",
    "    setRegParam(0.0).\\\n",
    "    setMaxIter(100).\\\n",
    "    setElasticNetParam(0.)\n",
    "\n",
    "# pipeline with tweets_pre_proc_pipe and logistic regression \n",
    "lr_pipe = Pipeline(stages=[tweets_pre_proc_pipe, lr]).fit(training_df)\n",
    "\n",
    "# AUC score\n",
    "evaluator = BinaryClassificationEvaluator(labelCol='target')\n",
    "AUC_score = evaluator.evaluate(lr_pipe.transform(testing_df))\n",
    "print('AUC Score: ', AUC_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 701
    },
    "id": "e68lThdufk3-",
    "outputId": "79b052d8-e9cf-4cee-a9bf-31b690b1283e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adopted</td>\n",
       "      <td>-8.641777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>selfish</td>\n",
       "      <td>-8.157059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>depressed</td>\n",
       "      <td>-6.644970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>update:</td>\n",
       "      <td>-6.311959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>brutal</td>\n",
       "      <td>-6.265906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@milliemagsaysay</td>\n",
       "      <td>-6.040053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pirates</td>\n",
       "      <td>-5.925209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>why'd</td>\n",
       "      <td>-5.904686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dec</td>\n",
       "      <td>-5.894391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>last!</td>\n",
       "      <td>-5.765711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               word    weight\n",
       "0           adopted -8.641777\n",
       "1           selfish -8.157059\n",
       "2         depressed -6.644970\n",
       "3           update: -6.311959\n",
       "4            brutal -6.265906\n",
       "5  @milliemagsaysay -6.040053\n",
       "6           pirates -5.925209\n",
       "7             why'd -5.904686\n",
       "8               dec -5.894391\n",
       "9             last! -5.765711"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ja</td>\n",
       "      <td>7.734643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lotr</td>\n",
       "      <td>7.166360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pizza?</td>\n",
       "      <td>6.978478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>participating</td>\n",
       "      <td>6.635875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ride!</td>\n",
       "      <td>6.511661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>anyway..</td>\n",
       "      <td>5.679254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>marvelous</td>\n",
       "      <td>5.619924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>demi.</td>\n",
       "      <td>5.526293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ch?</td>\n",
       "      <td>5.113280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>kidding,</td>\n",
       "      <td>5.059666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word    weight\n",
       "0             ja  7.734643\n",
       "1           lotr  7.166360\n",
       "2         pizza?  6.978478\n",
       "3  participating  6.635875\n",
       "4          ride!  6.511661\n",
       "5       anyway..  5.679254\n",
       "6      marvelous  5.619924\n",
       "7          demi.  5.526293\n",
       "8            ch?  5.113280\n",
       "9       kidding,  5.059666"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(lr_pipe_df_neg)\n",
    "display(lr_pipe_df_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HZ16kRRdfk4A"
   },
   "source": [
    "The words do not make sense. For both most positive and negative vocabs, there are meaningless words such as user ids and URL. However, there are some words that make sense as well such as selfish in negative dataframe and marvelous in positive dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 479
    },
    "id": "9-tqtjSdfk4B",
    "outputId": "ed29efd4-f18c-41a8-f008-81b18ccaa959"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model 1\n",
      "Fitting model 2\n",
      "Fitting model 3\n",
      "Fitting model 4\n",
      "Fitting model 5\n",
      "Fitting model 6\n",
      "Fitting model 7\n",
      "Fitting model 8\n",
      "Fitting model 9\n",
      "Fitting model 10\n",
      "Fitting model 11\n",
      "Fitting model 12\n",
      "Fitting model 13\n",
      "Fitting model 14\n",
      "Fitting model 15\n",
      "Fitting model 16\n",
      "Fitting model 17\n",
      "Fitting model 18\n",
      "Fitting model 19\n",
      "Fitting model 20\n",
      "Fitting model 21\n",
      "Fitting model 22\n",
      "Fitting model 23\n",
      "Fitting model 24\n",
      "Fitting model 25\n",
      "Parameters of the best model:  {Param(parent='LogisticRegression_4b8864a2264b', name='regParam', doc='regularization parameter (>= 0).'): 0.02, Param(parent='LogisticRegression_4b8864a2264b', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.1}\n"
     ]
    }
   ],
   "source": [
    "if enable_grid:\n",
    "    # your grid search code here\n",
    "    lr_pipe_1 = Pipeline(stages=[tweets_pre_proc_pipe, lr])\n",
    "\n",
    "    # initiate grid\n",
    "    grid = ParamGridBuilder().\\\n",
    "    addGrid(lr.regParam, [0., 0.01, 0.02, 0.03, 0.04]).\\\n",
    "    addGrid(lr.elasticNetParam, [0., 0.1, 0.2, 0.3, 0.4]).\\\n",
    "    build()\n",
    "\n",
    "    # iterate over the number of grid and train the models\n",
    "    all_models = []\n",
    "    for j in range(len(grid)):\n",
    "      print(\"Fitting model {}\".format(j+1))\n",
    "      model = lr_pipe_1.fit(training_df, grid[j])\n",
    "      all_models.append(model)\n",
    "\n",
    "    # calculate AUC scores for all trained models using validation data\n",
    "    AUCs = [BinaryClassificationEvaluator(labelCol='target').\\\n",
    "            evaluate(m.transform(validation_df)) for m in all_models]\n",
    "    \n",
    "    # find the index of highest AUC score\n",
    "    best_model_idx = np.argmax(AUCs)\n",
    "    # find the best model\n",
    "    best_model = all_models[best_model_idx]\n",
    "    # locate the best model to find the best parameters\n",
    "    print('Parameters of the best model: ', grid[best_model_idx])\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "id": "b1TcOogezK1y",
    "outputId": "e4ccfd54-1b93-43da-a4d0-ffb78387ba38"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7302954648970297,\n",
       " 0.7302957645361232,\n",
       " 0.7302919161862773,\n",
       " 0.730292604908969,\n",
       " 0.7302958047861509,\n",
       " 0.7712411112062999,\n",
       " 0.8073725836633938,\n",
       " 0.8161951794849792,\n",
       " 0.813898041099142,\n",
       " 0.8070612340483104,\n",
       " 0.7772219544651257,\n",
       " 0.8168137486151079,\n",
       " 0.8074927858981366,\n",
       " 0.7900602619833144,\n",
       " 0.7730768165691578,\n",
       " 0.7807339706099314,\n",
       " 0.814836564405777,\n",
       " 0.7905057336342987,\n",
       " 0.7647323910736319,\n",
       " 0.7447048696254198,\n",
       " 0.7831853716981808,\n",
       " 0.8081937177649827,\n",
       " 0.7741475008409127,\n",
       " 0.7449124703225365,\n",
       " 0.7171341620891506]"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "xdK0sc2Jfk4F",
    "outputId": "2d0a884c-ab5f-4c78-bae8-5f117c8037a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score:  0.8184283717773866\n"
     ]
    }
   ],
   "source": [
    "# parameters from the best model\n",
    "alpha_par = 0.02\n",
    "lambda_par = 0.1\n",
    "\n",
    "# lr_pipe_2 code here\n",
    "lr_2 = LogisticRegression().\\\n",
    "        setLabelCol('target').\\\n",
    "        setFeaturesCol('tfidf').\\\n",
    "        setRegParam(alpha_par).\\\n",
    "        setMaxIter(100).\\\n",
    "        setElasticNetParam(lambda_par)\n",
    "\n",
    "lr_pipe_2 = Pipeline(stages=[tweets_pre_proc_pipe, lr_2]).fit(training_df)\n",
    "\n",
    "# report AUC score with testing data\n",
    "evaluator = BinaryClassificationEvaluator(labelCol='target')\n",
    "AUC_score_2 = evaluator.evaluate(lr_pipe_2.transform(testing_df))\n",
    "print('AUC Score: ', AUC_score_2)\n",
    "\n",
    "compare_dict = {'model_name':['lr_pipe', 'lr_pipe_2'], 'auc_score':[AUC_score, AUC_score_2]}\n",
    "comapre_1_df = pd.DataFrame.from_dict(compare_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "id": "uSPnMUCHfk4H",
    "outputId": "d21d744c-c202-48d1-afcf-f7092d182070"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>auc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr_pipe</td>\n",
       "      <td>0.723576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lr_pipe_2</td>\n",
       "      <td>0.818428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_name  auc_score\n",
       "0    lr_pipe   0.723576\n",
       "1  lr_pipe_2   0.818428"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(comapre_1_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "vHMutpytfk4K",
    "outputId": "431f4254-e27b-4977-8529-d994a308bda7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words eliminated:  0\n"
     ]
    }
   ],
   "source": [
    "vocab_lr_pipe_1 = lr_pipe.stages[0].stages[2].vocabulary\n",
    "vocab_lr_pipe_2 = lr_pipe_2.stages[0].stages[2].vocabulary\n",
    "print(\"Number of words eliminated: \", len(vocab_lr_pipe_1)-len(vocab_lr_pipe_2 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tyyopb10fk4N"
   },
   "outputs": [],
   "source": [
    "# weights from the best model\n",
    "weights_2 = lr_pipe_2.stages[-1].coefficients.toArray()\n",
    "\n",
    "lr_pipe_2_df = pd.DataFrame({'word':vocab_lr_pipe_2, 'weights': weights_2})\n",
    "\n",
    "lr_pipe_df_neg_1 = lr_pipe_2_df.sort_values('weights').reset_index(drop=True).head(10)\n",
    "lr_pipe_df_pos_1 = lr_pipe_2_df.sort_values('weights', ascending=False).reset_index(drop=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 701
    },
    "id": "5Jr5WSjofk4P",
    "outputId": "c64d9338-97c8-4a7a-dae6-e39c025b055b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sad</td>\n",
       "      <td>-0.450782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>miss</td>\n",
       "      <td>-0.330157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>poor</td>\n",
       "      <td>-0.328874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wish</td>\n",
       "      <td>-0.323344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>missing</td>\n",
       "      <td>-0.315183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sick</td>\n",
       "      <td>-0.308480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hurts</td>\n",
       "      <td>-0.305853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sucks</td>\n",
       "      <td>-0.304261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lost</td>\n",
       "      <td>-0.287978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sad.</td>\n",
       "      <td>-0.283056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word   weights\n",
       "0      sad -0.450782\n",
       "1     miss -0.330157\n",
       "2     poor -0.328874\n",
       "3     wish -0.323344\n",
       "4  missing -0.315183\n",
       "5     sick -0.308480\n",
       "6    hurts -0.305853\n",
       "7    sucks -0.304261\n",
       "8     lost -0.287978\n",
       "9     sad. -0.283056"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thanks</td>\n",
       "      <td>0.308825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>guilt</td>\n",
       "      <td>0.283446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thank</td>\n",
       "      <td>0.281859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>welcome</td>\n",
       "      <td>0.272772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>owners</td>\n",
       "      <td>0.253157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wiff</td>\n",
       "      <td>0.247450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>good</td>\n",
       "      <td>0.237222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>kiddos</td>\n",
       "      <td>0.234237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>peaceful</td>\n",
       "      <td>0.227550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>@jonthanjay</td>\n",
       "      <td>0.224960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word   weights\n",
       "0       thanks  0.308825\n",
       "1        guilt  0.283446\n",
       "2        thank  0.281859\n",
       "3      welcome  0.272772\n",
       "4       owners  0.253157\n",
       "5         wiff  0.247450\n",
       "6         good  0.237222\n",
       "7       kiddos  0.234237\n",
       "8     peaceful  0.227550\n",
       "9  @jonthanjay  0.224960"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(lr_pipe_df_neg_1)\n",
    "display(lr_pipe_df_pos_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1dzdpwewfk4S"
   },
   "source": [
    "Now, positive words are indeed positive and negative words are indeed negative. Additionally, more negative word is assigned to a more negative weights. For example, the words 'sad' has the most negative weights, and the word 'sad' does have more negative connotation than 'miss' or 'sucks'. However, there are still rooms for improvements. The words 'sad.' is same as 'sad', but they appear twice with different weights. Also, in lr_pipe_df_pos_1, the word 'guilt' is ranked second highest weights, but 'guilt' is not a positive word. '@jonthanjay' is ranked 10th, but it does not mean anything. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "zJ9rpQAxfk4T",
    "outputId": "264078c6-d5cd-4be6-aa18-3f643174e7ee"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr = lr_pipe_2.stages[-1].summary.roc.select('FPR').collect()\n",
    "tpr = lr_pipe_2.stages[-1].summary.roc.select('TPR').collect()\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dZksMG7wfk4V"
   },
   "source": [
    "In order to plot a ROC curve, True Positive Rate (TPR) and False Positive Rate (FPR) need to be calculated from the confusion matrix. TPR is calculated by dividing the True Positive by true condition positive. The formula for FPR is 1-(TNR), which is 1-(True Negative / true condition negative). TPR and FPR are calculated across the range of threshold where the threshold is compared against the model probability prediction. Then, the resulting data is plotted as TPR in y axis and FPR in x axis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "JQj0SE13fk4X",
    "outputId": "8b8c9369-50b5-4430-d6ae-060e2a8be78b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "recall = lr_pipe_2.stages[-1].summary.pr.select('recall').collect()\n",
    "precision = fpr = lr_pipe_2.stages[-1].summary.pr.select('precision').collect()\n",
    "\n",
    "plt.plot(recall, precision)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision/Recall Curve')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nDgag3WKfk4Z"
   },
   "source": [
    "*   In Precision / Recall curve, recall is equivalent to TPR in the ROC curve.Precision is calculated by dividing TP by predicted condition positive. Both ROC curve and Precision/Recall curve are useful tool for evaluating binary classification model. Both ROC curve and Precision/Recall curve have TPR or recall axis. \n",
    "*   Precision axis is used in PR curve and FPR is used in ROC curve. This means, in terms of calculation, PR curve does not deal with True Negative in any ways. ROC curve is more useful when there is roughly equal number of observations for each class. In contrast, Precision/Recall curve should be used when there is a moderate to large class imbalance. \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "IST-718 Fall 2020 Homework 4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
